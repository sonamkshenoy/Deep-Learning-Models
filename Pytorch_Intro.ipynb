{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch Intro.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPG7KDjMiuM8h7HM0pQAOtF"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRzGqAfCHJEZ",
        "colab_type": "text"
      },
      "source": [
        "## Outline\n",
        "1. PyTorch\n",
        "2. What are tensors\n",
        "3. Initialising, slicing, reshaping tensors\n",
        "4. Numpy and PyTorch interfacing\n",
        "5. GPU support for PyTorch + Enabling GPUs on Google Colab\n",
        "6. Speed comparisons, NumPy - PyTorch - PyTorch on GPU\n",
        "7. Autograd concepts and application\n",
        "8. Writing basic learning loop using autograd\n",
        "9. Exercises"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X31EJ8GOHEm0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXyXBsohKu2R",
        "colab_type": "text"
      },
      "source": [
        "All operations very similar to NumPy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qA3N0pAnJTnh",
        "colab_type": "text"
      },
      "source": [
        "# Initialise tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kR3BC52dKlbg",
        "colab_type": "text"
      },
      "source": [
        "Initialise using in-built functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxYWGdEUJRZx",
        "colab_type": "code",
        "outputId": "dcc89174-71aa-45a6-f644-ab5af2288997",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "x = torch.ones(3,2)\n",
        "print(x)\n",
        "x = torch.zeros(3,2)\n",
        "print(x)\n",
        "x = torch.rand(3,2)\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]])\n",
            "tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]])\n",
            "tensor([[0.9766, 0.0918],\n",
            "        [0.1453, 0.3810],\n",
            "        [0.4336, 0.8751]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwZQch3tJq1H",
        "colab_type": "code",
        "outputId": "ba065595-1ce9-4131-a8e4-b8ea64d1a7a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "x = torch.empty(3,2)\n",
        "# Creates space but doesn't initialise values in it. So just has the values which were there initially in memory (could be NaN too)\n",
        "print(x)\n",
        "y = torch.zeros_like(x)\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2.1517e-36, 0.0000e+00],\n",
            "        [3.3631e-44, 0.0000e+00],\n",
            "        [       nan, 0.0000e+00]])\n",
            "tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcD1WnrEKDND",
        "colab_type": "code",
        "outputId": "75cd2648-d664-47a0-a292-2085677dcbf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x = torch.linspace(0,1, steps = 5)\n",
        "# Include 0 and 1\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gS1uJLtEKgf6",
        "colab_type": "text"
      },
      "source": [
        "Initialising manually"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3Nv6T15KW1j",
        "colab_type": "code",
        "outputId": "f2af5820-581b-4154-f79d-23cee10f5674",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "x = torch.tensor([[1,2],\n",
        "                  [3,4],\n",
        "                  [5,6]])\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCUEn81wKdYn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hw9edf8bKqjl",
        "colab_type": "text"
      },
      "source": [
        "# Slicing tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egUJ3ka5KrtD",
        "colab_type": "code",
        "outputId": "a8bb8c51-0adf-4260-a68c-b594ac8fcc7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "print(x.size()) # like x.shape in numpy\n",
        "print(x[:,1])\n",
        "print(x[0,:])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 2])\n",
            "tensor([2, 4, 6])\n",
            "tensor([1, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54yUINKLK5Wr",
        "colab_type": "code",
        "outputId": "1f209329-0152-4baa-d1b4-ab0c9ab013e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "y = x[1,1]\n",
        "print(y) # y is still of type tensor\n",
        "print(y.item()) # To get numerical/scalar value of a tensor"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(4)\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxexZJNQLDfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fd507UL8LJ9I",
        "colab_type": "text"
      },
      "source": [
        "# Reshaping tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwAbrnNRLLTl",
        "colab_type": "code",
        "outputId": "058efd6d-e1b2-4fda-f313-3d8ab88ba747",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "print(x)\n",
        "y = x.view(2,3) # Similar to numpy.reshape()\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tbosypq1LQ2R",
        "colab_type": "code",
        "outputId": "8b4ce7e0-ec05-4ea0-d6d3-fccd350cb473",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "y = x.view(6, -1) # when we want particularly one dimension as we want (6) and it can fix the other dimension suitably to fit all items itself (-1)\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1],\n",
            "        [2],\n",
            "        [3],\n",
            "        [4],\n",
            "        [5],\n",
            "        [6]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yu3MD6DPLny8",
        "colab_type": "text"
      },
      "source": [
        "Mismatch in tensor dimensions biggest bug in tensor-world/DL. And knowing what each axis means (input/batch/weight)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFKxG0hTLzSx",
        "colab_type": "text"
      },
      "source": [
        "# Simple Tensor Operations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojsvTBFKLdq7",
        "colab_type": "code",
        "outputId": "91105015-cf0c-4a0f-fb5e-83151ef4a0e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "# Pointwirse Operations\n",
        "x = torch.ones([3,2])\n",
        "y = torch.ones([3,2])\n",
        "z = x + y\n",
        "print(z)\n",
        "z = x-y\n",
        "print(z)\n",
        "z = x*y\n",
        "print(z)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2., 2.],\n",
            "        [2., 2.],\n",
            "        [2., 2.]])\n",
            "tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]])\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Et93hyv1MD_M",
        "colab_type": "code",
        "outputId": "6bcfe41e-61c1-4afd-ed73-c30f40c2ace2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "z = y.add(x)\n",
        "print(z)\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2., 2.],\n",
            "        [2., 2.],\n",
            "        [2., 2.]])\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWrjvvRLMVOW",
        "colab_type": "code",
        "outputId": "146b3253-5073-4274-bd31-834c8e7ea063",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "z = y.add_(x) # Modifies y too (_ => modify-in-place). Adds x to y. z modified as well\n",
        "print(z)\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2., 2.],\n",
            "        [2., 2.],\n",
            "        [2., 2.]])\n",
            "tensor([[2., 2.],\n",
            "        [2., 2.],\n",
            "        [2., 2.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfgZNat0Mh0u",
        "colab_type": "text"
      },
      "source": [
        "Useful if don't want to generate new tensors everytime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwXQfE2oNOIX",
        "colab_type": "text"
      },
      "source": [
        "# Numpy <> PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Adz7V9RKNqbq",
        "colab_type": "text"
      },
      "source": [
        "Converting PyTorch to NumPy array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AN8J_o_gNTcF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "8e085b92-dec6-47bb-cfa1-6a8d55a62c9c"
      },
      "source": [
        "# We initialised x above as a numpy 3x2 ones\n",
        "x_np = x.numpy()\n",
        "print(type(x), type(x_np))\n",
        "print(x_np)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'> <class 'numpy.ndarray'>\n",
            "[[1. 1.]\n",
            " [1. 1.]\n",
            " [1. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XWoB38ONt4x",
        "colab_type": "text"
      },
      "source": [
        "Converting NumPy array to PyTorch tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBMMg-aVNbDi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "c4508a3f-2bf7-482a-9438-54d92b704d0e"
      },
      "source": [
        "a = np.random.randn(5)\n",
        "print(a)\n",
        "a_pt = torch.from_numpy(a)\n",
        "print(type(a), type(a_pt))\n",
        "print(a_pt)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.29573148 -0.15142621  1.43368774  0.96222957 -0.51295352]\n",
            "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n",
            "tensor([ 0.2957, -0.1514,  1.4337,  0.9622, -0.5130], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIy_VDTBOECi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "2c142435-a6e9-4598-b956-1fa7ba73640b"
      },
      "source": [
        "np.add(a, 1, out=a)\n",
        "print(a)\n",
        "print(a_pt)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.29573148 0.84857379 2.43368774 1.96222957 0.48704648]\n",
            "tensor([1.2957, 0.8486, 2.4337, 1.9622, 0.4870], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrLHkLfLOR7u",
        "colab_type": "text"
      },
      "source": [
        "Though we added only to a, a_pt got updated too. Since we just did bridging, not copying. Therefore change in one affects the other. They refer the same underlying numerical store. Very useful if you want to perform operations suitable to one of the types. Or if there is some code in NumPy, can easily transform it to tensor, operate and we'll still be able to use the code on it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3CR5huMOQnv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "efca2bd5-cb7e-471c-f0b2-c0804559fcfa"
      },
      "source": [
        "%%time\n",
        "for i in range(100):\n",
        "  a = np.random.randn(100, 100)\n",
        "  b = np.random.randn(100, 100)\n",
        "  c = a + b"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 102 ms, sys: 105 µs, total: 103 ms\n",
            "Wall time: 106 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-icPPcehPF9z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "8a7fb2ee-09da-4ee1-ea01-2a46bf198cd2"
      },
      "source": [
        "%%time\n",
        "for i in range(100):\n",
        "  a = torch.randn([100,100])\n",
        "  b = torch.randn([100,100])\n",
        "  c = a + b"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 21 ms, sys: 872 µs, total: 21.8 ms\n",
            "Wall time: 26.5 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3P6dnjVUPetK",
        "colab_type": "text"
      },
      "source": [
        "Still CPU, not GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgfBKoOePqRi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "108a1e52-52d6-4512-bedb-f9ede7276089"
      },
      "source": [
        "%%time\n",
        "for i in range(100):\n",
        "  a = np.random.randn(100, 100)\n",
        "  b = np.random.randn(100, 100)\n",
        "  c = np.matmul(a, b)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 163 ms, sys: 117 ms, total: 279 ms\n",
            "Wall time: 155 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aMbxluLPssn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "0a957cee-3470-4da7-e30e-ff03ddea650a"
      },
      "source": [
        "%%time\n",
        "for i in range(100):\n",
        "  a = torch.randn([100,100])\n",
        "  b = torch.randn([100,100])\n",
        "  c = torch.matmul(a,b)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 24.1 ms, sys: 1.09 ms, total: 25.1 ms\n",
            "Wall time: 84.1 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhiX4FOcPPnR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "e71d46c9-eaa1-4491-ba72-655220723e80"
      },
      "source": [
        "%%time\n",
        "for i in range(10):\n",
        "  a = np.random.randn(1000, 1000)\n",
        "  b = np.random.randn(1000, 1000)\n",
        "  c = a+b"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 965 ms, sys: 10.4 ms, total: 976 ms\n",
            "Wall time: 978 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-GwzHPZQC3s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "10d9d3b3-3350-4b27-e6a8-28acdc395751"
      },
      "source": [
        "%%time\n",
        "for i in range(10):\n",
        "  a = torch.randn([1000,1000])\n",
        "  b = torch.randn([1000,1000])\n",
        "  c = a + b"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 169 ms, sys: 887 µs, total: 169 ms\n",
            "Wall time: 173 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7Zch40GQTWB",
        "colab_type": "text"
      },
      "source": [
        "Huge improvement from Python to Numpy.  \n",
        "Then additional huge improvement from NumPy to PyTorch.  \n",
        "And now amazingly more using Cuda"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NG3wgZiEQHf7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8ZybuqMQiKD",
        "colab_type": "text"
      },
      "source": [
        "# CUDA support"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTFQdbkYQpNG",
        "colab_type": "text"
      },
      "source": [
        "CUDA is language extension by NVidia to support programming GPUs directly.  \n",
        "Cuda extension for C and Photon."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0adgJ4eKQkei",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "404d8572-ca28-40da-fe25-dc9021f1f4b9"
      },
      "source": [
        "# Check if we have GPU in our system (first include : Edit > Notebook Settings)\n",
        "# RAM also increases (larger hard disk)\n",
        "print(torch.cuda.device_count())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtSrfZ9vQxTX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "056fc843-70ea-45fe-b9f2-fabc6e115be4"
      },
      "source": [
        "print(torch.cuda.device(0))\n",
        "print(torch.cuda.get_device_name(0))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<torch.cuda.device object at 0x7f4f92793908>\n",
            "Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qA46ayjpRHXL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We got to know that there is a GPU at location 0, so mention 0\n",
        "cuda0 = torch.device('cuda:0')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bb_jOs_FR2_C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "acb850d9-6293-4c07-c51a-9b96db991ff6"
      },
      "source": [
        "a = torch.ones(3, 2, device = cuda0)\n",
        "b = torch.ones(3, 2, device = cuda0)\n",
        "c = a + b\n",
        "print(c)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2., 2.],\n",
            "        [2., 2.],\n",
            "        [2., 2.]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sdt28YRSbWN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "805632d1-df40-4fb3-993e-3fcd1cf0d40b"
      },
      "source": [
        "print(a)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoOcXuxESMQF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "a8ff5f6f-e4b1-4224-a5e4-2918850245f4"
      },
      "source": [
        "%%time\n",
        "for i in range(10):\n",
        "  a_cpu = torch.randn([10000,10000])\n",
        "  b_cpu = torch.randn([10000,10000])\n",
        "  b_cpu.add(a_cpu)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 14.2 s, sys: 484 ms, total: 14.6 s\n",
            "Wall time: 14.7 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzUfyTgFSU6p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "3feae13b-5e38-4e9f-fcca-af9014e0efb3"
      },
      "source": [
        "%%time\n",
        "for i in range(10):\n",
        "  a_gpu = torch.randn([10000,10000],device = cuda0)\n",
        "  b_gpu = torch.randn([10000,10000],device = cuda0)\n",
        "  b_gpu.add(a_gpu)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 555 µs, sys: 2.06 ms, total: 2.61 ms\n",
            "Wall time: 10.3 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54pUfAb9TCoG",
        "colab_type": "text"
      },
      "source": [
        "1000 times improvement!!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zJzfKh1S0re",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "5699ec83-5dca-473b-dabf-5a7ecfad09d5"
      },
      "source": [
        "%%time\n",
        "for i in range(100):\n",
        "  a_cpu = torch.randn([10000,10000])\n",
        "  b_cpu = torch.randn([10000,10000])\n",
        "  torch.matmul(a_cpu,b_cpu)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 22min 33s, sys: 1.05 s, total: 22min 34s\n",
            "Wall time: 22min 34s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiKvwArnTaU2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "598649f5-547b-4edd-a8fc-976b65569f4b"
      },
      "source": [
        "%%time\n",
        "for i in range(100):\n",
        "  a_gpu = torch.randn([10000,10000], device = cuda0)\n",
        "  b_gpu = torch.randn([10000,10000], device = cuda0)\n",
        "  torch.matmul(a_gpu,b_gpu)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 7 ms, sys: 2 ms, total: 9 ms\n",
            "Wall time: 13.9 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlPrcBJXaSqw",
        "colab_type": "text"
      },
      "source": [
        "22 minutes versus 13 ms !!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abPveuuOTf_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upIDl7JnW4Xt",
        "colab_type": "text"
      },
      "source": [
        "# Autograd"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHZlFKogW6QZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "017f651c-ad33-4994-fee3-8df4b6d234e5"
      },
      "source": [
        "x = torch.ones([3,2], requires_grad = True) # Telling PyTorch x is something which could be differentiated against\n",
        "print(x)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rx5dB818XEWT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "cf277528-577b-4fce-958c-7a49e1806f01"
      },
      "source": [
        "y = x + 5\n",
        "print(y)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[6., 6.],\n",
            "        [6., 6.],\n",
            "        [6., 6.]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-xJUG5mXX0P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "1eb25035-2d49-4782-b8d2-e942d952b85c"
      },
      "source": [
        "z = y*y + 1\n",
        "print(z)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[37., 37.],\n",
            "        [37., 37.],\n",
            "        [37., 37.]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcNhy6GwXdZx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e90b317e-62be-4c18-d284-7a286b824d19"
      },
      "source": [
        "# Similar to forward pass where y is func of x, z is func of y, t is func of z\n",
        "t = torch.sum(z)\n",
        "print(t)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(222., grad_fn=<SumBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFZLBoJNXobL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now do backward pass since t is func of x\n",
        "t.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp2fD7zIXsZT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "ffade0be-b431-466b-bf94-e67174af648e"
      },
      "source": [
        "# Prints the Derivative of t w.r.t. x\n",
        "print(x.grad)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[12., 12.],\n",
            "        [12., 12.],\n",
            "        [12., 12.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXzjzXjzalfy",
        "colab_type": "text"
      },
      "source": [
        "The derivative is 2yi*1  \n",
        "Here xi=1 (first matrix) and yi=6 (second matrix)  \n",
        "Hence x.gradi = 12"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGyc136oak73",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "outputId": "698f7b48-4311-47de-81c9-cb286679ce9f"
      },
      "source": [
        "x = torch.ones([3,2], requires_grad = True)\n",
        "y = x+5\n",
        "r = 1/(1+torch.exp(-y))\n",
        "print(r)\n",
        "s = torch.sum(r) # Adds all values of r => tensor with single value in it\n",
        "print(s)\n",
        "s.backward()\n",
        "print(x.grad)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.9975, 0.9975],\n",
            "        [0.9975, 0.9975],\n",
            "        [0.9975, 0.9975]], grad_fn=<MulBackward0>)\n",
            "tensor(5.9852, grad_fn=<SumBackward0>)\n",
            "tensor([[0.0025, 0.0025],\n",
            "        [0.0025, 0.0025],\n",
            "        [0.0025, 0.0025]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTlocxZvb_vZ",
        "colab_type": "text"
      },
      "source": [
        "We so far called artificially summed r in s. And then called backward on it.  \n",
        "Instead can do r.backward() directly but error.  \n",
        "Since whenever you are doing x.backward() where x has multiple values, backward must have an argument.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mT5yEK0Y2ys",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "12255d69-ecd4-49a1-96fe-887e203c1229"
      },
      "source": [
        "x = torch.ones([3,2], requires_grad = True)\n",
        "y = x+5\n",
        "r = 1/(1+torch.exp(-y))\n",
        "print(r)\n",
        "a = torch.ones([3,2])#Same size as r\n",
        "r.backward(a)\n",
        "print(x.grad)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.9975, 0.9975],\n",
            "        [0.9975, 0.9975],\n",
            "        [0.9975, 0.9975]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0025, 0.0025],\n",
            "        [0.0025, 0.0025],\n",
            "        [0.0025, 0.0025]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fncDnkO9ccSs",
        "colab_type": "text"
      },
      "source": [
        "Same result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvI8ZqlRcdi4",
        "colab_type": "text"
      },
      "source": [
        "r.backward() is computing grad of r w.r.t. x  \n",
        "But we are multiplying result pointwise with a (here ones, so value remains same as grad of r w.r.t. x  \n",
        "Why required : to cascade chain rule through multiple functions.  \n",
        "e.g. ds/dx = ds/dr * dr/dx  \n",
        "r.backward is dr/dx  \n",
        "And the a represents ds/dr which we don't have here. (later)  \n",
        "s represents a tensor coming from up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XtpavVPcajp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYmoT2oXdS6h",
        "colab_type": "text"
      },
      "source": [
        "## Autograd example that looks like what we have been doing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrM3SHatdYRP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}